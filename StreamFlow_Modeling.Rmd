---
title: "Untitled"
author: "Victoria Cutler"
date: "2023-05-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(sensitivity)
library(tidyverse)
library(lubridate)
library(reldist)
library(purrr)
library(ggpubr)

source("R/cper.R")
source("R/nse.R")
source("R/relerr.R")
source("R/summer_flow_accuracy.R")
```

```{r}
summer_months = c(5, 6, 7, 8, 9)

streamflow_data_model <- sager |> 
  filter(month == summer_months) |> 
  group_by(year) |> 
  summarise(average_flow_obs = mean(obs),
            average_flow_mod = mean(model)) |> 
  select(average_flow_mod)

streamflow_data_obs <- sager |> 
  filter(month == summer_months) |> 
  group_by(year) |> 
  summarise(average_flow_obs = mean(obs),
            average_flow_mod = mean(model)) |> 
  select(average_flow_obs)

summer_flow_accuracy(streamflow_data_model, streamflow_data_obs)
```

```{r read in data}
sager = read.table("Data/sager.txt", header=T)
head(sager)

# add date
sager = sager |>  mutate(date = paste(day,month,year, sep="/"))
sager$date = as.Date(sager$date,"%d/%m/%Y")
```

# Assignment

Final piece will be to produce a graph of maximum likelihood estimate given you acceptable parameters!

To hand in - an Rmarkdown and R function. Please knit and turn in either an html or pdf of the markdown. 

* Part 1 from above: R function that codes a metric for performance evaluation 
  * must be a combination of at least two performance measures
  * include some comments that explain 'why' this metric
  
* R markdown that does the following steps (with lots of documentation of the work flow):

  * Part 2 from above: 
    1. Apply your performance function to a subset of the Sagehen data set (with multiple simulations) that you want to use for calibration 
    
```{r}
#each column  is streamflow for a different parameter set
msage = read.table("Data/sagerm.txt", header=T)

# keep track of number of simulations (e.g results for each parameter set) 
# use as a column names
nsim = ncol(msage)
snames = sprintf("S%d",seq(from=1, to=nsim))
colnames(msage)=snames


# lets say we know the start date from our earlier output
msage$date = sager$date
msage$month = sager$month
msage$year = sager$year
msage$day = sager$day
msage$wy = sager$wy

# lets add observed
msage = left_join(msage, sager[,c("obs","date")], by=c("date"))

head(msage)

# subset for split sample calibration
short_msage = subset(msage, wy < 1975)

# compute performance measures for output from all parameters
res = short_msage %>% select(!c("date","month","year","day","wy","obs")) %>%
      map_df(summer_flow_accuracy(), o = short_msage$obs) # purrr function here! map_dbl will apply the function nse() to each column in our data frame against the observed and returns a vector

best = res[which.max(res)]

worst = res[which.min(res)]
```
    
    2. Summarize the performance over the calibration period in 1-2 graphs; you can decide what is useful 
  
  * Part 3  
    3. Use the performance measure to select "acceptable" outcomes from parameter sets (see #15 in contents)
    4. Compute the range of the performance measure using only the "acceptable" outcomes over the post-calibration period (part that you didn't use for calibration in step 1)
    5. Graph the range of outcomes for acceptable parameters (e.g post-calibration parameter uncertainty); you can choose what output is most interesting for you 
    6. Compute and graph the maximum likelihood estimate of your output of interest (e.g minimum summer streamflow each year) for the post-calibration period (see #16 or #17 in contents)
  
  * Part 4: A short paragraph discussing why you choose the output and performance measures that you did and some thoughts (1-2 sentences) on what your calibration and post-calibration uncertainty analysis tells you
  
# Rubric 60 pts 

* R function (10pts) 
  * combines at least 2 performance metrics (5)
  * function is applied to part of Sagehen data set (5)
  
* Calibration (20pts)
  * your metrics are used to select 'acceptable' parameter set outcomes (5)
  * metrics are computed for post-calibration data of accepted parameter set outcomes (5)
  * maximum likelihood estimate is computed for post-calibration data (10)
  
* Graphs (20pts)
  * 1-2 plots of summary of performance over calibration period (5) 
  * 1-2 plots of output of acceptable parameter sets that clearly visualize uncertainty (5)
  * plot maximum likelihood estimate for post-calibration period (5) 
  * graphing style (axis labels, legibility) (5)
  
* Discussion (10pts)
  * short explanation on metrics used (5) 
  * 1-2 sentences on calibration and post-calibration uncertainty analysis 